{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn.metrics import confusion_matrix \r\n",
    "from sklearn import tree\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from imblearn.over_sampling import SMOTE\r\n",
    "#from sklearn.metrics import plot_confusion_matrix\r\n",
    "\r\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CleanedEV.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = df.drop(columns=['HFUEL'])\n",
    "dataY = df[['HFUEL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "GaussianNB(var_smoothing=1.0)\n",
      "0.9799196787148594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1220\n",
      "           1       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.98      1245\n",
      "   macro avg       0.49      0.50      0.49      1245\n",
      "weighted avg       0.96      0.98      0.97      1245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chom\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\Chom\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Chom\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Chom\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(priors=None, var_smoothing=1.0)\r\n",
    "param_grid_nb = {\r\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\r\n",
    "}\r\n",
    "nbModel_grid = GridSearchCV(estimator=gnb, param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\r\n",
    "nbModel_grid.fit(X_train, y_train)\r\n",
    "print(nbModel_grid.best_estimator_)\r\n",
    "print(nbModel_grid.score(X_test, y_test))\r\n",
    "\r\n",
    "y_pred = nbModel_grid.predict(X_test) \r\n",
    "print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pumping the weight by Using SMOTE with Naive bays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX_over = df.drop(columns=['HFUEL'])\r\n",
    "dataY_over = df[['HFUEL']]\r\n",
    "Over_Sample = SMOTE()\r\n",
    "dataX_over , dataY_over = Over_Sample.fit_resample(dataX_over,dataY_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_over, X_test_over, y_train_over, y_test_over = train_test_split(dataX_over, dataY_over, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n",
      "GaussianNB()\n",
      "0.556013179571664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.20      0.31      1217\n",
      "           1       0.53      0.92      0.67      1211\n",
      "\n",
      "    accuracy                           0.56      2428\n",
      "   macro avg       0.62      0.56      0.49      2428\n",
      "weighted avg       0.62      0.56      0.49      2428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(priors=None, var_smoothing=1.0)\r\n",
    "param_grid_nb = {\r\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\r\n",
    "}\r\n",
    "nbModel_grid = GridSearchCV(estimator=gnb, param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)\r\n",
    "nbModel_grid.fit(X_train_over, y_train_over)\r\n",
    "print(nbModel_grid.best_estimator_)\r\n",
    "print(nbModel_grid.score(X_test_over, y_test_over))\r\n",
    "\r\n",
    "y_pred = nbModel_grid.predict(X_test_over) \r\n",
    "print(classification_report(y_test_over,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,confusion_matrix,classification_report,plot_confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis1 = LogisticRegression()\n",
    "classifier = model_logis1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_test = model_logis1.predict(X_test)\n",
    "acc=format(accuracy_score(y_test,ypred_test), \"0.2%\")\n",
    "print(\"Accuracy : \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(classifier, X_test, y_test, display_labels=[\"0\", \"1\"],cmap=plt.cm.Blues)\n",
    "print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oversampling = df.drop(columns=['HFUEL']) #SMOTE\n",
    "y_oversampling = df[['HFUEL']]\n",
    "Oversampling = SMOTE()\n",
    "X_oversampling , y_oversampling = Oversampling.fit_resample(X_oversampling,y_oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "\n",
    "for i in df.drop(columns=['HFUEL']):\n",
    "  name.append(i)\n",
    "\n",
    "df_new = pd.DataFrame(data = X_oversampling, columns= name)\n",
    "df_new['HFUEL'] = y_oversampling\n",
    "\n",
    "print(df.groupby(['HFUEL']).size().reset_index(name='counts'))\n",
    "print(df_new.groupby(['HFUEL']).size().reset_index(name='counts')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainO, X_testO, y_trainO, y_testO = train_test_split(X_oversampling, y_oversampling, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logis2 = LogisticRegression()\n",
    "classifier = model_logis2.fit(X_trainO,y_trainO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_test = model_logis2.predict(X_testO)\n",
    "acc=format(accuracy_score(y_testO,ypred_test), \"0.2%\")\n",
    "print(\"Accuracy : \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_confusion_matrix(classifier, X_testO, y_testO, display_labels=[\"CV\", \"EV\"],cmap=plt.cm.Blues)\n",
    "print(disp.confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_testO,ypred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "\n",
    "\n",
    "\n",
    "#Using GridSearchCV\n",
    "model = GridSearchCV(LogisticRegression(penalty='l2'), tuned_parameters, scoring = 'roc_auc', cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(model.best_estimator_)\n",
    "print(model.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "language_info": {},
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}